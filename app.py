from flask import Flask, render_template, request, redirect, url_for, flash, session, jsonify
import os
import pandas as pd
from datetime import datetime, timedelta
import hashlib
import secrets
from functools import wraps

# å®‰å…¨å¯¼å…¥ qrcode æ¨¡å—
import sys
current_dir = os.getcwd()
if current_dir in sys.path:
    sys.path.remove(current_dir)

import qrcode

# åˆ›å»º Flask åº”ç”¨å®ä¾‹
app = Flask(__name__)

# è®¾ç½®å¯†é’¥ç”¨äº session å’Œ flash æ¶ˆæ¯
app.secret_key = 'points-management-system-secret-key-2024'

# é…ç½®ä¸Šä¼ æ–‡ä»¶å¤¹
UPLOAD_FOLDER = 'uploads'
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# ç”¨æˆ·æ•°æ®æ–‡ä»¶
USERS_FILE = 'users.csv'

# åˆå§‹åŒ–ç”¨æˆ·æ•°æ®æ–‡ä»¶
def init_users_file():
    """åˆå§‹åŒ–ç”¨æˆ·æ•°æ®æ–‡ä»¶"""
    if not os.path.exists(USERS_FILE):
        # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜è´¦æˆ·
        default_users = pd.DataFrame({
            'username': ['admin'],
            'password_hash': [hash_password('admin123')],
            'email': ['admin@example.com'],
            'role': ['admin'],
            'created_at': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
            'is_active': [True]
        })
        default_users.to_csv(USERS_FILE, index=False)

def hash_password(password):
    """å¯†ç å“ˆå¸Œ"""
    return hashlib.sha256(password.encode()).hexdigest()

def verify_password(password, password_hash):
    """éªŒè¯å¯†ç """
    return hash_password(password) == password_hash

def login_required(f):
    """ç™»å½•è£…é¥°å™¨"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

def get_current_user():
    """è·å–å½“å‰ç™»å½•ç”¨æˆ·"""
    if 'user_id' not in session:
        return None

    try:
        users_df = pd.read_csv(USERS_FILE)
        user = users_df[users_df['username'] == session['user_id']]
        if not user.empty:
            return user.iloc[0].to_dict()
    except:
        pass
    return None

def create_user(username, password, email, role='user'):
    """åˆ›å»ºæ–°ç”¨æˆ·"""
    try:
        users_df = pd.read_csv(USERS_FILE)

        # æ£€æŸ¥ç”¨æˆ·åæ˜¯å¦å·²å­˜åœ¨
        if not users_df[users_df['username'] == username].empty:
            return False, "ç”¨æˆ·åå·²å­˜åœ¨"

        # æ£€æŸ¥é‚®ç®±æ˜¯å¦å·²å­˜åœ¨
        if not users_df[users_df['email'] == email].empty:
            return False, "é‚®ç®±å·²å­˜åœ¨"

        # æ·»åŠ æ–°ç”¨æˆ·
        new_user = pd.DataFrame({
            'username': [username],
            'password_hash': [hash_password(password)],
            'email': [email],
            'role': [role],
            'created_at': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
            'is_active': [True]
        })

        users_df = pd.concat([users_df, new_user], ignore_index=True)
        users_df.to_csv(USERS_FILE, index=False)

        return True, "ç”¨æˆ·åˆ›å»ºæˆåŠŸ"
    except Exception as e:
        return False, f"åˆ›å»ºç”¨æˆ·å¤±è´¥: {str(e)}"

# åˆå§‹åŒ–ç”¨æˆ·æ•°æ®æ–‡ä»¶
init_users_file()
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# é…ç½®äºŒç»´ç ä¿å­˜æ–‡ä»¶å¤¹
QR_FOLDER = 'static/qr_codes'
if not os.path.exists(QR_FOLDER):
    os.makedirs(QR_FOLDER)
app.config['QR_FOLDER'] = QR_FOLDER

def generate_general_qr_code(query_url):
    """
    ç”Ÿæˆé€šç”¨æŸ¥è¯¢äºŒç»´ç 
    """
    filename = "general_query_qr.png"
    file_path = os.path.join(app.config['QR_FOLDER'], filename)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(app.config['QR_FOLDER'], exist_ok=True)

    try:
        # åˆ›å»ºäºŒç»´ç å®ä¾‹
        qr = qrcode.QRCode(
            version=1,
            error_correction=qrcode.constants.ERROR_CORRECT_L,
            box_size=10,
            border=4,
        )

        # æ·»åŠ æ•°æ®
        qr.add_data(query_url)
        qr.make(fit=True)

        # ç”Ÿæˆå›¾ç‰‡
        img = qr.make_image(fill_color="black", back_color="white")
        img.save(file_path)

        return {
            'query_url': query_url,
            'filename': filename,
            'file_path': file_path,
            'web_path': f"/static/qr_codes/{filename}"
        }

    except Exception as e:
        print(f"âŒ é€šç”¨äºŒç»´ç ç”Ÿæˆå¤±è´¥: {e}")
        raise Exception(str(e))

def process_points_accumulation(new_points, daily_stats, user_info_df=None):
    """
    å¤„ç†ç§¯åˆ†ç´¯è®¡å’Œ90å¤©è¿‡æœŸæœºåˆ¶
    """
    from datetime import datetime, timedelta

    # å½“å‰æ—¥æœŸ
    current_date = datetime.now().date()
    cutoff_date = current_date - timedelta(days=90)

    # è¯»å–å½“å‰ç”¨æˆ·çš„å†å²ç§¯åˆ†è®°å½•
    points_history_file = get_user_data_path('points_history.csv')
    if os.path.exists(points_history_file):
        history_df = pd.read_csv(points_history_file)
        history_df['Date'] = pd.to_datetime(history_df['Date']).dt.date
        history_df['UserID'] = history_df['UserID'].astype(str)
    else:
        # åˆ›å»ºç©ºçš„å†å²è®°å½•
        history_df = pd.DataFrame(columns=['UserID', 'Date', 'Points'])

    # æ·»åŠ æ–°çš„ç§¯åˆ†è®°å½•ï¼ˆæ£€æŸ¥é‡å¤ï¼‰
    new_records = []
    for _, row in daily_stats.iterrows():
        user_id = str(row['UserID'])
        date = row['Date']

        # æ£€æŸ¥è¯¥ç”¨æˆ·åœ¨è¯¥æ—¥æœŸæ˜¯å¦å·²æœ‰è®°å½•
        existing_record = history_df[
            (history_df['UserID'] == user_id) &
            (history_df['Date'] == date)
        ]

        # å¦‚æœæ²¡æœ‰è®°å½•ï¼Œåˆ™æ·»åŠ æ–°è®°å½•
        if existing_record.empty:
            new_records.append({
                'UserID': user_id,
                'Date': date,
                'Points': 1  # æ¯å¤©æœ€å¤š1åˆ†
            })

    if new_records:
        new_df = pd.DataFrame(new_records)
        history_df = pd.concat([history_df, new_df], ignore_index=True)
        print(f"âœ… æ·»åŠ äº† {len(new_records)} æ¡æ–°çš„ç§¯åˆ†è®°å½•")

    # ç§»é™¤90å¤©å‰çš„ç§¯åˆ†è®°å½•
    history_df = history_df[history_df['Date'] > cutoff_date]

    # å»é‡ï¼ˆåŒä¸€ç”¨æˆ·åŒä¸€å¤©åªèƒ½æœ‰ä¸€æ¡è®°å½•ï¼‰
    history_df = history_df.drop_duplicates(subset=['UserID', 'Date'], keep='last')

    # ä¿å­˜æ›´æ–°åçš„å†å²è®°å½•
    history_df.to_csv(points_history_file, index=False)

    # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„æ€»ç§¯åˆ†
    user_points = history_df.groupby('UserID')['Points'].sum().reset_index()
    user_points.columns = ['UserID', 'TotalPoints']
    user_points['UserID'] = user_points['UserID'].astype(str)

    # æ·»åŠ æœ‰æ•ˆæœŸä¿¡æ¯
    user_points['ValidDays'] = history_df.groupby('UserID').size().reset_index(name='ValidDays')['ValidDays']

    # æ·»åŠ ç”¨æˆ·æ˜µç§°ä¿¡æ¯
    if user_info_df is not None and 'UserName' in user_info_df.columns:
        # è·å–æ¯ä¸ªç”¨æˆ·çš„æœ€æ–°æ˜µç§°
        user_names = user_info_df.groupby('UserID')['UserName'].last().reset_index()
        user_names['UserID'] = user_names['UserID'].astype(str)
        user_points = user_points.merge(user_names, on='UserID', how='left')
        user_points['UserName'] = user_points['UserName'].fillna('æœªçŸ¥ç”¨æˆ·')
    else:
        user_points['UserName'] = 'æœªçŸ¥ç”¨æˆ·'

    # ä¿å­˜å½“å‰ç”¨æˆ·çš„ç§¯åˆ†æ–‡ä»¶
    user_points_file = get_user_data_path('user_points.csv')
    user_points.to_csv(user_points_file, index=False)

    return user_points

def get_user_data_path(filename, user_id=None):
    """
    è·å–ç”¨æˆ·ä¸“å±çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    """
    if user_id is None:
        user_id = session.get('user_id', 'default')

    # åˆ›å»ºç”¨æˆ·ä¸“å±ç›®å½•
    user_dir = os.path.join('data', user_id)
    if not os.path.exists(user_dir):
        os.makedirs(user_dir)

    return os.path.join(user_dir, filename)

def get_system_stats():
    """
    è·å–ç³»ç»Ÿç»Ÿè®¡æ•°æ®ï¼ˆå½“å‰ç”¨æˆ·çš„æ•°æ®ï¼‰
    """
    try:
        stats = {
            'total_users': 0,
            'total_points': 0,
            'active_users': 0
        }

        # è¯»å–å½“å‰ç”¨æˆ·çš„ç§¯åˆ†æ•°æ®
        user_points_file = get_user_data_path('user_points.csv')
        if os.path.exists(user_points_file):
            user_points = pd.read_csv(user_points_file)

            # æ€»ç”¨æˆ·æ•°
            stats['total_users'] = len(user_points)

            # ç´¯è®¡ç§¯åˆ†
            stats['total_points'] = int(user_points['TotalPoints'].sum())

            # æ´»è·ƒç”¨æˆ·æ•°ï¼ˆç§¯åˆ†>0çš„ç”¨æˆ·ï¼‰
            stats['active_users'] = len(user_points[user_points['TotalPoints'] > 0])

        return stats

    except Exception as e:
        print(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}")
        return {
            'total_users': 0,
            'total_points': 0,
            'active_users': 0
        }

def extract_date_from_data(df):
    """
    ä»æ•°æ®ä¸­æå–æ—¥æœŸä¿¡æ¯ï¼Œæ”¯æŒå¤šç§æ—¥æœŸæ ¼å¼å’Œå†å²æ•°æ®
    """
    from datetime import datetime, timedelta

    date_column = None

    # ä¼˜å…ˆä½¿ç”¨å¼€å§‹æ—¶é—´
    if 'StartTime' in df.columns:
        date_column = 'StartTime'
    elif 'EndTime' in df.columns:
        date_column = 'EndTime'

    if date_column and pd.api.types.is_datetime64_any_dtype(df[date_column]):
        # å¦‚æœå·²ç»æ˜¯datetimeç±»å‹ï¼Œç›´æ¥æå–æ—¥æœŸ
        df['Date'] = df[date_column].dt.date
    elif date_column:
        # å°è¯•è§£ææ—¶é—´å­—ç¬¦ä¸²
        try:
            df['Date'] = pd.to_datetime(df[date_column]).dt.date
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
            df['Date'] = datetime.now().date()
            print(f"âš ï¸ è­¦å‘Š: æ— æ³•è§£ææ—¶é—´åˆ— {date_column}ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ")
    else:
        # æ²¡æœ‰æ—¶é—´åˆ—ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½çš„æ—¥æœŸåˆ—
        possible_date_columns = [col for col in df.columns if 'æ—¶é—´' in col or 'æ—¥æœŸ' in col or 'date' in col.lower() or 'time' in col.lower()]

        if possible_date_columns:
            # å°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯èƒ½çš„æ—¥æœŸåˆ—
            try:
                df['Date'] = pd.to_datetime(df[possible_date_columns[0]]).dt.date
                print(f"âœ… ä½¿ç”¨åˆ— '{possible_date_columns[0]}' ä½œä¸ºæ—¥æœŸ")
            except:
                df['Date'] = datetime.now().date()
                print(f"âš ï¸ è­¦å‘Š: æ— æ³•è§£ææ—¥æœŸåˆ— {possible_date_columns[0]}ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ")
        else:
            # å®Œå…¨æ²¡æœ‰æ—¥æœŸä¿¡æ¯ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
            df['Date'] = datetime.now().date()
            print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•æ—¥æœŸåˆ—ï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ")

    return df

def process_historical_data(df, cutoff_days=90):
    """
    å¤„ç†å†å²æ•°æ®ï¼Œç¡®ä¿åªä¿ç•™æŒ‡å®šå¤©æ•°å†…çš„æ•°æ®
    """
    from datetime import datetime, timedelta

    current_date = datetime.now().date()
    cutoff_date = current_date - timedelta(days=cutoff_days)

    # è¿‡æ»¤æ‰è¶…è¿‡æœ‰æ•ˆæœŸçš„æ•°æ®
    if 'Date' in df.columns:
        original_count = len(df)
        df = df[df['Date'] > cutoff_date]
        filtered_count = len(df)

        if original_count > filtered_count:
            expired_count = original_count - filtered_count
            print(f"ğŸ“… è¿‡æ»¤æ‰ {expired_count} æ¡è¶…è¿‡ {cutoff_days} å¤©çš„å†å²æ•°æ®")
            print(f"   ä¿ç•™ {filtered_count} æ¡æœ‰æ•ˆæ•°æ®ï¼ˆ{cutoff_date} ä¹‹åï¼‰")

    return df

def clean_empty_data(df):
    """
    æ¸…ç†ç©ºæ•°æ®å’Œæ— æ•ˆè¡Œ
    """
    print(f"ğŸ“Š æ•°æ®æ¸…ç†å‰: {len(df)} è¡Œ")

    # 1. åˆ é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
    df = df.dropna(how='all')
    print(f"ğŸ“Š åˆ é™¤å®Œå…¨ç©ºè¡Œå: {len(df)} è¡Œ")

    # 2. æ¸…ç†ç©ºå­—ç¬¦ä¸²å’Œç©ºæ ¼
    # å°†ç©ºå­—ç¬¦ä¸²å’ŒåªåŒ…å«ç©ºæ ¼çš„å­—ç¬¦ä¸²æ›¿æ¢ä¸ºNaN
    df = df.replace(r'^\s*$', pd.NA, regex=True)

    # 3. è¯†åˆ«å…³é”®åˆ—
    user_id_columns = [col for col in df.columns if any(keyword in col for keyword in ['ç”¨æˆ·', 'user', 'id', 'ID', 'ç¼–å·'])]
    duration_columns = [col for col in df.columns if any(keyword in col for keyword in ['æ—¶é•¿', 'æ—¶é—´', 'duration', 'time'])]
    name_columns = [col for col in df.columns if any(keyword in col for keyword in ['æ˜µç§°', 'name', 'åç§°', 'å§“å'])]

    print(f"ğŸ“‹ è¯†åˆ«çš„å…³é”®åˆ—:")
    print(f"   ç”¨æˆ·IDåˆ—: {user_id_columns}")
    print(f"   æ—¶é•¿åˆ—: {duration_columns}")
    print(f"   ç”¨æˆ·ååˆ—: {name_columns}")

    # 4. åˆ é™¤ç”¨æˆ·IDä¸ºç©ºçš„è¡Œï¼ˆç”¨æˆ·IDæ˜¯å¿…éœ€çš„ï¼‰
    if user_id_columns:
        for col in user_id_columns[:1]:  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªç”¨æˆ·IDåˆ—
            before_count = len(df)
            df = df.dropna(subset=[col])
            after_count = len(df)
            if before_count != after_count:
                print(f"ğŸ“Š åˆ é™¤{col}ä¸ºç©ºçš„è¡Œ: {before_count} â†’ {after_count} è¡Œ")

    # 5. åˆ é™¤æ—¶é•¿ä¸ºç©ºçš„è¡Œï¼ˆæ—¶é•¿æ˜¯å¿…éœ€çš„ï¼‰
    if duration_columns:
        for col in duration_columns[:1]:  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªæ—¶é•¿åˆ—
            before_count = len(df)
            df = df.dropna(subset=[col])
            after_count = len(df)
            if before_count != after_count:
                print(f"ğŸ“Š åˆ é™¤{col}ä¸ºç©ºçš„è¡Œ: {before_count} â†’ {after_count} è¡Œ")

    # 6. åˆ é™¤æ‰€æœ‰é‡è¦åˆ—éƒ½ä¸ºç©ºçš„è¡Œ
    important_columns = user_id_columns + duration_columns + name_columns
    if important_columns:
        before_count = len(df)
        df = df.dropna(subset=important_columns, how='all')
        after_count = len(df)
        if before_count != after_count:
            print(f"ğŸ“Š åˆ é™¤é‡è¦åˆ—å…¨ç©ºçš„è¡Œ: {before_count} â†’ {after_count} è¡Œ")

    # 7. åˆ é™¤é‡å¤è¡Œ
    before_count = len(df)
    df = df.drop_duplicates()
    after_count = len(df)
    if before_count != after_count:
        print(f"ğŸ“Š åˆ é™¤é‡å¤è¡Œ: {before_count} â†’ {after_count} è¡Œ")

    # 8. å†æ¬¡åˆ é™¤å¯èƒ½äº§ç”Ÿçš„ç©ºè¡Œ
    df = df.dropna(how='all')

    # 9. é‡ç½®ç´¢å¼•
    df = df.reset_index(drop=True)

    print(f"ğŸ“Š æ•°æ®æ¸…ç†å®Œæˆ: {len(df)} è¡Œæœ‰æ•ˆæ•°æ®")

    # æ˜¾ç¤ºæ¸…ç†åçš„æ•°æ®æ¦‚è§ˆ
    if len(df) > 0:
        print(f"ğŸ“‹ æ¸…ç†åæ•°æ®æ¦‚è§ˆ:")
        print(f"   åˆ—æ•°: {len(df.columns)}")
        print(f"   åˆ—å: {list(df.columns)}")
        if len(df) <= 10:
            print(f"   æ‰€æœ‰æ•°æ®è¡Œ:")
            for i, (_, row) in enumerate(df.iterrows()):
                row_preview = " | ".join([f"{col}: {str(row[col])[:20]}" for col in df.columns[:3]])
                print(f"      ç¬¬{i+1}è¡Œ: {row_preview}")
        else:
            print(f"   å‰3è¡Œæ•°æ®:")
            for i, (_, row) in enumerate(df.head(3).iterrows()):
                row_preview = " | ".join([f"{col}: {str(row[col])[:20]}" for col in df.columns[:3]])
                print(f"      ç¬¬{i+1}è¡Œ: {row_preview}")

    return df

def filter_and_paginate_user_points(user_points, page, per_page, search_user_id, search_user_name, min_points, max_points, sort_by, sort_order):
    """
    å¯¹ç”¨æˆ·ç§¯åˆ†æ•°æ®è¿›è¡Œç­›é€‰å’Œåˆ†é¡µå¤„ç†
    """
    # è½¬æ¢ä¸ºDataFrameä»¥ä¾¿å¤„ç†
    df = user_points.copy()

    # ç¡®ä¿æœ‰UserNameåˆ—
    if 'UserName' not in df.columns:
        df['UserName'] = 'æœªçŸ¥ç”¨æˆ·'

    # åº”ç”¨ç­›é€‰æ¡ä»¶
    if search_user_id:
        df = df[df['UserID'].astype(str).str.contains(search_user_id, case=False, na=False)]

    if search_user_name:
        df = df[df['UserName'].str.contains(search_user_name, case=False, na=False)]

    if min_points is not None:
        df = df[df['TotalPoints'] >= min_points]

    if max_points is not None:
        df = df[df['TotalPoints'] <= max_points]

    # æ’åº
    ascending = sort_order == 'asc'
    if sort_by in df.columns:
        df = df.sort_values(sort_by, ascending=ascending)

    # è®¡ç®—åˆ†é¡µ
    total_records = len(df)
    total_pages = (total_records + per_page - 1) // per_page
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    paginated_data = df.iloc[start_idx:end_idx]

    return {
        'data': paginated_data,
        'total_records': total_records,
        'total_pages': total_pages
    }

def detect_column_mapping(columns):
    """
    æ™ºèƒ½è¯†åˆ«è¡¨æ ¼åˆ—åï¼Œæ”¯æŒå¤šç§è¡¨å¤´æ ¼å¼
    è¿”å›åˆ—åæ˜ å°„å­—å…¸
    """
    column_list = [col.strip() for col in columns]
    mapping = {}

    # ç”¨æˆ·IDç›¸å…³çš„å¯èƒ½åˆ—å
    user_id_patterns = [
        'ç”¨æˆ·id', 'ç”¨æˆ·ID', 'UserID', 'userid', 'user_id',
        'ä¸»æ’­ID', 'ä¸»æ’­id', 'æ¼”å‘˜ID', 'æ¼”å‘˜id'
    ]

    # ç”¨æˆ·æ˜µç§°ç›¸å…³çš„å¯èƒ½åˆ—å
    user_name_patterns = [
        'æ¼”å‘˜äººå¤§å', 'æ¼”å‘˜äººåå­—', 'ç”¨æˆ·åç§°', 'ç”¨æˆ·é…ç§°', 'ç”¨æˆ·æ˜µç§°', 'æ˜µç§°', 'å§“å',
        'ä¸»æ’­', 'ä¸»æ’­å', 'æ¼”å‘˜', 'ç”¨æˆ·', 'ç”¨æˆ·å', 'username', 'nickname'
    ]

    # å¼€å§‹æ—¶é—´ç›¸å…³çš„å¯èƒ½åˆ—å
    start_time_patterns = [
        'é¦–æ¬¡è§‚çœ‹ç›´æ’­æ—¶é—´', 'å¼€å§‹æ—¶é—´', 'StartTime', 'start_time', 'starttime',
        'ç›´æ’­å¼€å§‹æ—¶é—´', 'å¼€æ’­æ—¶é—´', 'é¦–æ¬¡è¿›å…¥æ—¶é—´', 'è¿›å…¥æ—¶é—´', 'å¼€å§‹'
    ]

    # ç»“æŸæ—¶é—´ç›¸å…³çš„å¯èƒ½åˆ—å
    end_time_patterns = [
        'æœ€åè§‚çœ‹ç›´æ’­æ—¶é—´', 'æœ€è¿‘è§‚çœ‹ç›´æ’­æ—¶é—´', 'æœ€åç¦»å¼€ç›´æ’­æ—¶é—´', 'ç»“æŸæ—¶é—´', 'EndTime', 'end_time', 'endtime',
        'ç›´æ’­ç»“æŸæ—¶é—´', 'ç¦»å¼€æ—¶é—´', 'ç»“æŸ'
    ]

    # è§‚çœ‹æ—¶é•¿ç›¸å…³çš„å¯èƒ½åˆ—å
    duration_patterns = [
        'ç›´æ’­è§‚çœ‹æ—¶é•¿', 'è§‚çœ‹æ—¶é•¿', 'æ—¶é•¿', 'Duration', 'duration',
        'è§‚çœ‹æ—¶é—´', 'ç›´æ’­æ—¶é—´', 'åœ¨çº¿æ—¶é•¿', 'åœç•™æ—¶é•¿'
    ]

    def find_best_match(column_list, patterns, mapping_key):
        """æŸ¥æ‰¾æœ€ä½³åŒ¹é…çš„åˆ—"""
        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        for col in column_list:
            col_lower = col.lower()
            for pattern in patterns:
                pattern_lower = pattern.lower()
                if col_lower == pattern_lower:
                    return col

        # ç„¶åå°è¯•åŒ…å«åŒ¹é…
        for col in column_list:
            col_lower = col.lower()
            for pattern in patterns:
                pattern_lower = pattern.lower()
                if pattern_lower in col_lower:
                    return col

        return None

    # æŸ¥æ‰¾å„ç§åˆ—
    user_id_col = find_best_match(column_list, user_id_patterns, 'UserID')
    if user_id_col:
        mapping[user_id_col] = 'UserID'

    user_name_col = find_best_match(column_list, user_name_patterns, 'UserName')
    if user_name_col:
        mapping[user_name_col] = 'UserName'

    start_time_col = find_best_match(column_list, start_time_patterns, 'StartTime')
    if start_time_col:
        mapping[start_time_col] = 'StartTime'

    end_time_col = find_best_match(column_list, end_time_patterns, 'EndTime')
    if end_time_col:
        mapping[end_time_col] = 'EndTime'

    duration_col = find_best_match(column_list, duration_patterns, 'Duration')
    if duration_col:
        mapping[duration_col] = 'Duration'

    # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†å¿…è¦çš„åˆ—
    found_mappings = set(mapping.values())

    # å¿…é¡»æœ‰ç”¨æˆ·ID
    if 'UserID' not in found_mappings:
        return None

    # å¿…é¡»æœ‰æ—¶é•¿ä¿¡æ¯ï¼šè¦ä¹ˆæœ‰Durationåˆ—ï¼Œè¦ä¹ˆæœ‰StartTimeå’ŒEndTimeåˆ—
    has_duration = 'Duration' in found_mappings
    has_time_range = 'StartTime' in found_mappings and 'EndTime' in found_mappings

    if has_duration or has_time_range:
        return mapping
    else:
        return None

def parse_duration_column(duration_series):
    """
    è§£ææ—¶é•¿åˆ—ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    ä¾‹å¦‚ï¼š'0å°æ—¶43åˆ†53ç§’', '1:30:45', '90åˆ†é’Ÿ' ç­‰
    """
    import re

    def parse_single_duration(duration_str):
        if pd.isna(duration_str):
            return None

        duration_str = str(duration_str).strip()

        # æ ¼å¼1: "0å°æ—¶43åˆ†53ç§’"
        chinese_pattern = r'(\d+)å°æ—¶(\d+)åˆ†(\d+)ç§’'
        match = re.search(chinese_pattern, duration_str)
        if match:
            hours, minutes, seconds = map(int, match.groups())
            return hours * 60 + minutes + seconds / 60

        # æ ¼å¼2: "43åˆ†53ç§’"
        chinese_pattern2 = r'(\d+)åˆ†(\d+)ç§’'
        match = re.search(chinese_pattern2, duration_str)
        if match:
            minutes, seconds = map(int, match.groups())
            return minutes + seconds / 60

        # æ ¼å¼3: "1:30:45" (æ—¶:åˆ†:ç§’)
        time_pattern = r'(\d+):(\d+):(\d+)'
        match = re.search(time_pattern, duration_str)
        if match:
            hours, minutes, seconds = map(int, match.groups())
            return hours * 60 + minutes + seconds / 60

        # æ ¼å¼4: "90:30" (åˆ†:ç§’)
        time_pattern2 = r'(\d+):(\d+)'
        match = re.search(time_pattern2, duration_str)
        if match:
            minutes, seconds = map(int, match.groups())
            return minutes + seconds / 60

        # æ ¼å¼5: "90åˆ†é’Ÿ" æˆ– "90åˆ†"
        minute_pattern = r'(\d+)åˆ†'
        match = re.search(minute_pattern, duration_str)
        if match:
            minutes = int(match.group(1))
            return minutes

        # æ ¼å¼6: çº¯æ•°å­—ï¼ˆå‡è®¾ä¸ºåˆ†é’Ÿï¼‰
        if duration_str.isdigit():
            return float(duration_str)

        # æ— æ³•è§£æ
        return None

    return duration_series.apply(parse_single_duration)

def parse_datetime_column(datetime_series):
    """
    è§£ææ—¶é—´åˆ—ï¼Œæ”¯æŒå¤šç§æ—¶é—´æ ¼å¼
    """
    def parse_single_datetime(datetime_str):
        if pd.isna(datetime_str):
            return None

        datetime_str = str(datetime_str).strip()

        # å¸¸è§çš„æ—¶é—´æ ¼å¼åˆ—è¡¨
        time_formats = [
            '%Y-%m-%d %H:%M:%S',      # 2023-03-10 17:05:35
            '%Y/%m/%d %H:%M:%S',      # 2023/03/10 17:05:35
            '%Y-%m-%d %H:%M',         # 2023-03-10 17:05
            '%Y/%m/%d %H:%M',         # 2023/03/10 17:05
            '%Y-%m-%d',               # 2023-03-10
            '%Y/%m/%d',               # 2023/03/10
            '%m/%d/%Y %H:%M:%S',      # 03/10/2023 17:05:35
            '%m-%d-%Y %H:%M:%S',      # 03-10-2023 17:05:35
            '%d/%m/%Y %H:%M:%S',      # 10/03/2023 17:05:35
            '%d-%m-%Y %H:%M:%S',      # 10-03-2023 17:05:35
        ]

        # å°è¯•å„ç§æ ¼å¼
        for fmt in time_formats:
            try:
                return pd.to_datetime(datetime_str, format=fmt)
            except:
                continue

        # å¦‚æœæ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥ï¼Œå°è¯•pandasçš„æ™ºèƒ½è§£æ
        try:
            return pd.to_datetime(datetime_str, errors='coerce')
        except:
            return None

    return datetime_series.apply(parse_single_datetime)

def process_uploaded_file(file_path):
    """
    å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ï¼Œæ”¯æŒ CSVã€Excel ç­‰æ ¼å¼ï¼Œè®¡ç®—ç§¯åˆ†
    """
    try:
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è¯»å–æ–¹æ³•
        file_extension = os.path.splitext(file_path)[1].lower()

        if file_extension == '.csv':
            df = pd.read_csv(file_path, encoding='utf-8-sig')
        elif file_extension in ['.xlsx', '.xls']:
            df = pd.read_excel(file_path)
        elif file_extension == '.json':
            df = pd.read_json(file_path)
        elif file_extension == '.tsv':
            df = pd.read_csv(file_path, sep='\t', encoding='utf-8-sig')
        else:
            return {
                'success': False,
                'error': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}ã€‚æ”¯æŒçš„æ ¼å¼: .csv, .xlsx, .xls, .json, .tsv'
            }

        print(f"ğŸ“Š åŸå§‹æ–‡ä»¶è¯»å–: {len(df)} è¡Œ")

        # æ¸…ç†ç©ºæ•°æ®å’Œæ— æ•ˆè¡Œ
        df = clean_empty_data(df)

        if df.empty:
            return {
                'success': False,
                'error': 'æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹'
            }

        # æ™ºèƒ½è¯†åˆ«åˆ—åï¼Œæ”¯æŒå¤šç§è¡¨å¤´æ ¼å¼
        column_mapping = detect_column_mapping(df.columns)
        if not column_mapping:
            return {
                'success': False,
                'error': f'æ— æ³•è¯†åˆ«è¡¨æ ¼ç»“æ„ã€‚è¯·ç¡®ä¿åŒ…å«ç”¨æˆ·IDã€å¼€å§‹æ—¶é—´ã€ç»“æŸæ—¶é—´ç›¸å…³çš„åˆ—ã€‚\nå½“å‰åˆ—å: {list(df.columns)}'
            }

        # é‡å‘½ååˆ—ä¸ºæ ‡å‡†æ ¼å¼
        df = df.rename(columns=column_mapping)

        # å¤„ç†æ•°æ®
        try:
            df['UserID'] = df['UserID'].astype(str)

            # å¤„ç†æ—¶é•¿æ•°æ® - æ”¯æŒä¸¤ç§æ–¹å¼
            if 'Duration' in df.columns:
                # æ–¹å¼1ï¼šç›´æ¥ä½¿ç”¨è§‚çœ‹æ—¶é•¿åˆ—
                df['Duration'] = parse_duration_column(df['Duration'])
                # ç§»é™¤æ—¶é•¿è§£æå¤±è´¥çš„è¡Œ
                df = df.dropna(subset=['Duration'])
            else:
                # æ–¹å¼2ï¼šä½¿ç”¨å¼€å§‹å’Œç»“æŸæ—¶é—´è®¡ç®—æ—¶é•¿
                df['StartTime'] = parse_datetime_column(df['StartTime'])
                df['EndTime'] = parse_datetime_column(df['EndTime'])

                # ç§»é™¤æ—¶é—´è§£æå¤±è´¥çš„è¡Œ
                df = df.dropna(subset=['StartTime', 'EndTime'])

                if df.empty:
                    return {
                        'success': False,
                        'error': 'æ—¶é—´æ•°æ®æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æå¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´'
                    }

                df['Duration'] = (df['EndTime'] - df['StartTime']).dt.total_seconds() / 60

            if df.empty:
                return {
                    'success': False,
                    'error': 'æ— æ³•è§£ææ—¶é•¿æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼'
                }

        except Exception as e:
            return {
                'success': False,
                'error': f'æ•°æ®å¤„ç†é”™è¯¯: {str(e)}'
            }

        # ç­›é€‰å¤§äºç­‰äº40åˆ†é’Ÿçš„è®°å½•
        filtered_df = df[df['Duration'] >= 40].copy()

        if filtered_df.empty:
            return {
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°æŒç»­æ—¶é•¿å¤§äºç­‰äº40åˆ†é’Ÿçš„ç›´æ’­è®°å½•'
            }

        # æå–æ—¥æœŸä¿¡æ¯ï¼ˆæ”¯æŒå†å²æ•°æ®ï¼‰
        filtered_df = extract_date_from_data(filtered_df)

        # å¤„ç†å†å²æ•°æ®ï¼ˆè¿‡æ»¤è¶…è¿‡90å¤©çš„æ•°æ®ï¼‰
        filtered_df = process_historical_data(filtered_df, cutoff_days=90)

        if filtered_df.empty:
            return {
                'success': False,
                'error': 'æ‰€æœ‰æ•°æ®éƒ½è¶…è¿‡äº†90å¤©æœ‰æ•ˆæœŸï¼Œæ— æ³•è·å¾—ç§¯åˆ†'
            }

        daily_stats = filtered_df.groupby(['UserID', 'Date']).size().reset_index(name='Count')
        new_points = daily_stats.groupby('UserID').size().reset_index(name='NewPoints')
        new_points['UserID'] = new_points['UserID'].astype(str)

        # å¤„ç†ç§¯åˆ†ç´¯è®¡å’Œè¿‡æœŸ
        user_points = process_points_accumulation(new_points, daily_stats, filtered_df)

        return {
            'success': True,
            'user_points': user_points,
            'total_users': len(user_points)
        }

    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

# å®šä¹‰æ ¹è·¯ç”±
# ç™»å½•è·¯ç”±
@app.route('/login', methods=['GET', 'POST'])
def login():
    """ç™»å½•é¡µé¢"""
    if request.method == 'POST':
        username = request.form.get('username', '').strip()
        password = request.form.get('password', '')

        if not username or not password:
            flash('è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ', 'error')
            return render_template('login.html')

        try:
            users_df = pd.read_csv(USERS_FILE)
            user = users_df[users_df['username'] == username]

            if user.empty:
                flash('ç”¨æˆ·åä¸å­˜åœ¨', 'error')
                return render_template('login.html')

            user_data = user.iloc[0]

            if not user_data['is_active']:
                flash('è´¦æˆ·å·²è¢«ç¦ç”¨', 'error')
                return render_template('login.html')

            if verify_password(password, user_data['password_hash']):
                session['user_id'] = username
                session['user_role'] = user_data['role']
                session['just_logged_in'] = True  # æ ‡è®°åˆšåˆšç™»å½•
                return redirect(url_for('admin_upload'))
            else:
                flash('å¯†ç é”™è¯¯', 'error')
                return render_template('login.html')

        except Exception as e:
            flash(f'ç™»å½•å¤±è´¥: {str(e)}', 'error')
            return render_template('login.html')

    return render_template('login.html')

# æ³¨å†Œè·¯ç”±
@app.route('/register', methods=['GET', 'POST'])
def register():
    """æ³¨å†Œé¡µé¢"""
    if request.method == 'POST':
        username = request.form.get('username', '').strip()
        email = request.form.get('email', '').strip()
        password = request.form.get('password', '')
        confirm_password = request.form.get('confirm_password', '')

        # éªŒè¯è¾“å…¥
        if not all([username, email, password, confirm_password]):
            flash('è¯·å¡«å†™æ‰€æœ‰å¿…å¡«å­—æ®µ', 'error')
            return render_template('register.html')

        if password != confirm_password:
            flash('ä¸¤æ¬¡è¾“å…¥çš„å¯†ç ä¸ä¸€è‡´', 'error')
            return render_template('register.html')

        if len(password) < 6:
            flash('å¯†ç è‡³å°‘éœ€è¦6ä¸ªå­—ç¬¦', 'error')
            return render_template('register.html')

        # åˆ›å»ºç”¨æˆ·
        success, message = create_user(username, password, email, 'admin')

        if success:
            flash('æ³¨å†ŒæˆåŠŸï¼è¯·ç™»å½•', 'success')
            return redirect(url_for('login'))
        else:
            flash(message, 'error')
            return render_template('register.html')

    return render_template('register.html')

# ç™»å‡ºè·¯ç”±
@app.route('/logout')
def logout():
    """ç™»å‡º"""
    session.clear()
    flash('å·²æˆåŠŸç™»å‡º', 'success')
    return redirect(url_for('home'))

@app.route('/')
def home():
    """
    ä¸»é¡µè·¯ç”±
    æ˜¾ç¤ºç³»ç»Ÿé¦–é¡µå’Œç»Ÿè®¡ä¿¡æ¯
    """
    try:
        # è·å–ç³»ç»Ÿç»Ÿè®¡æ•°æ®
        stats = get_system_stats()
        return render_template('index.html', stats=stats)
    except Exception as e:
        # å¦‚æœè·å–ç»Ÿè®¡æ•°æ®å¤±è´¥ï¼Œä»ç„¶æ˜¾ç¤ºé¦–é¡µä½†ä¸æ˜¾ç¤ºç»Ÿè®¡
        return render_template('index.html', stats=None)

# ç®¡ç†å‘˜ä¸Šä¼ é¡µé¢è·¯ç”±
@app.route('/admin/upload', methods=['GET', 'POST'])
@login_required
def admin_upload():
    """
    ç®¡ç†å‘˜ä¸Šä¼ é¡µé¢
    GET: æ˜¾ç¤ºä¸Šä¼ è¡¨å•
    POST: å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    """
    if request.method == 'GET':
        # æ£€æŸ¥æ˜¯å¦åˆšåˆšç™»å½•
        just_logged_in = session.pop('just_logged_in', False)
        current_user = get_current_user()

        # æ¸²æŸ“åˆå¹¶çš„ä¸Šä¼ é¡µé¢æ¨¡æ¿
        return render_template('admin_upload_combined.html',
                             show_results=False,
                             upload_result=None,
                             just_logged_in=just_logged_in,
                             current_user=current_user)

    elif request.method == 'POST':
        # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
        if 'file' not in request.files:
            flash('æ²¡æœ‰é€‰æ‹©æ–‡ä»¶', 'error')
            return redirect(request.url)

        file = request.files['file']

        # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†æ–‡ä»¶
        if file.filename == '':
            flash('æ²¡æœ‰é€‰æ‹©æ–‡ä»¶', 'error')
            return redirect(request.url)

        # æ£€æŸ¥æ–‡ä»¶ç±»å‹ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        allowed_extensions = ['.csv', '.xlsx', '.xls', '.json', '.tsv']
        file_extension = os.path.splitext(file.filename)[1].lower()

        if file and file_extension in allowed_extensions:
            # ä¿å­˜æ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{timestamp}_{file.filename}"
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(file_path)

            # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
            result = process_uploaded_file(file_path)

            if result['success']:
                user_points = result['user_points']
                base_url = request.host_url.rstrip('/')

                # ç”Ÿæˆé€šç”¨æŸ¥è¯¢äºŒç»´ç 
                general_qr_info = None
                try:
                    query_url = f"{base_url}/query"  # é€šç”¨æŸ¥è¯¢é¡µé¢
                    general_qr_info = generate_general_qr_code(query_url)
                except Exception as e:
                    flash(f'é€šç”¨äºŒç»´ç ç”Ÿæˆå¤±è´¥: {str(e)}', 'error')

                # ä¸ä½¿ç”¨flashæ¶ˆæ¯ï¼Œæ”¹ä¸ºåœ¨é¡µé¢å†…æ˜¾ç¤ºæˆåŠŸä¿¡æ¯

                # è·å–åˆ†é¡µå’Œç­›é€‰å‚æ•°
                page = request.args.get('page', 1, type=int)
                per_page = request.args.get('per_page', 10, type=int)
                search_user_id = request.args.get('search_user_id', '').strip()
                search_user_name = request.args.get('search_user_name', '').strip()
                min_points = request.args.get('min_points', type=int)
                max_points = request.args.get('max_points', type=int)
                sort_by = request.args.get('sort_by', 'TotalPoints')
                sort_order = request.args.get('sort_order', 'desc')

                # å¤„ç†ç”¨æˆ·ç§¯åˆ†æ•°æ®çš„åˆ†é¡µå’Œç­›é€‰
                filtered_user_points = filter_and_paginate_user_points(
                    user_points, page, per_page, search_user_id, search_user_name,
                    min_points, max_points, sort_by, sort_order
                )

                return render_template('admin_upload_combined.html',
                                     show_results=True,
                                     upload_result={
                                         'filename': filename,
                                         'total_users': result['total_users'],
                                         'user_points': filtered_user_points['data'],
                                         'total_records': filtered_user_points['total_records'],
                                         'total_pages': filtered_user_points['total_pages'],
                                         'current_page': page,
                                         'per_page': per_page,
                                         'general_qr': general_qr_info,
                                         'upload_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                         'search_params': {
                                             'search_user_id': search_user_id,
                                             'search_user_name': search_user_name,
                                             'min_points': min_points,
                                             'max_points': max_points,
                                             'sort_by': sort_by,
                                             'sort_order': sort_order
                                         }
                                     })
            else:
                flash(f'å¤„ç†å¤±è´¥: {result["error"]}', 'error')
                return redirect(request.url)
        else:
            flash(f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒçš„æ ¼å¼: {", ".join(allowed_extensions)}', 'error')
            return redirect(request.url)

# ç§¯åˆ†ç®¡ç†é¡µé¢
@app.route('/admin/points')
@login_required
def admin_points():
    """
    ç§¯åˆ†ç®¡ç†é¡µé¢ï¼ŒæŸ¥çœ‹ç§¯åˆ†å†å²å’Œè¿‡æœŸæƒ…å†µï¼Œæ”¯æŒåˆ†é¡µå’Œç­›é€‰
    """
    try:
        from datetime import datetime, timedelta

        # è·å–æŸ¥è¯¢å‚æ•°
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        search_user_id = request.args.get('search_user_id', '').strip()
        search_user_name = request.args.get('search_user_name', '').strip()
        min_points = request.args.get('min_points', type=int)
        max_points = request.args.get('max_points', type=int)
        sort_by = request.args.get('sort_by', 'TotalPoints')
        sort_order = request.args.get('sort_order', 'desc')

        # è¯»å–å½“å‰ç”¨æˆ·çš„ç§¯åˆ†æ•°æ®
        user_points_file = get_user_data_path('user_points.csv')
        if os.path.exists(user_points_file):
            user_stats = pd.read_csv(user_points_file)
            user_stats['UserID'] = user_stats['UserID'].astype(str)

            # ç¡®ä¿æœ‰UserNameåˆ—
            if 'UserName' not in user_stats.columns:
                user_stats['UserName'] = 'æœªçŸ¥ç”¨æˆ·'

            # åº”ç”¨ç­›é€‰æ¡ä»¶
            if search_user_id:
                user_stats = user_stats[user_stats['UserID'].str.contains(search_user_id, case=False, na=False)]

            if search_user_name:
                user_stats = user_stats[user_stats['UserName'].str.contains(search_user_name, case=False, na=False)]

            if min_points is not None:
                user_stats = user_stats[user_stats['TotalPoints'] >= min_points]

            if max_points is not None:
                user_stats = user_stats[user_stats['TotalPoints'] <= max_points]

            # æ’åº
            ascending = sort_order == 'asc'
            if sort_by in user_stats.columns:
                user_stats = user_stats.sort_values(sort_by, ascending=ascending)

            # è®¡ç®—åˆ†é¡µ
            total_records = len(user_stats)
            total_pages = (total_records + per_page - 1) // per_page
            start_idx = (page - 1) * per_page
            end_idx = start_idx + per_page
            paginated_stats = user_stats.iloc[start_idx:end_idx]

            # è¯»å–å†å²è®°å½•æ•°é‡
            points_history_file = 'points_history.csv'
            history_count = 0
            if os.path.exists(points_history_file):
                history_df = pd.read_csv(points_history_file)
                history_count = len(history_df)

            # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
            current_user = get_current_user()

            return render_template('admin_points.html',
                                 user_stats=paginated_stats,
                                 total_records=total_records,
                                 total_pages=total_pages,
                                 current_page=page,
                                 per_page=per_page,
                                 history_count=history_count,
                                 current_date=datetime.now().date(),
                                 current_user=current_user,
                                 search_params={
                                     'search_user_id': search_user_id,
                                     'search_user_name': search_user_name,
                                     'min_points': min_points,
                                     'max_points': max_points,
                                     'sort_by': sort_by,
                                     'sort_order': sort_order
                                 })
        else:
            # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
            current_user = get_current_user()

            return render_template('admin_points.html',
                                 user_stats=pd.DataFrame(),
                                 total_records=0,
                                 total_pages=0,
                                 current_page=1,
                                 per_page=per_page,
                                 history_count=0,
                                 current_date=datetime.now().date(),
                                 current_user=current_user,
                                 search_params={})
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"ç§¯åˆ†ç®¡ç†é¡µé¢é”™è¯¯: {error_details}")
        flash(f'è¯»å–ç§¯åˆ†æ•°æ®å¤±è´¥: {str(e)}', 'error')
        return redirect(url_for('admin_upload'))

# é€šç”¨æŸ¥è¯¢é¡µé¢
@app.route('/query')
def query_page():
    """
    é€šç”¨æŸ¥è¯¢é¡µé¢ï¼Œç”¨æˆ·å¯ä»¥è¾“å…¥ç”¨æˆ·åæŸ¥è¯¢ç§¯åˆ†
    """
    return render_template('query_page.html')

# ç”¨æˆ·æŸ¥è¯¢æ¥å£
@app.route('/query/<user_name>')
def query_user(user_name):
    """
    ç”¨æˆ·æŸ¥è¯¢æ¥å£ - æ ¹æ®ç”¨æˆ·åæŸ¥è¯¢
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•ç”¨æˆ·çš„æ•°æ®
        user_points_file = None
        if 'user_id' in session:
            user_points_file = get_user_data_path('user_points.csv')

        # å¦‚æœæ²¡æœ‰ç™»å½•ç”¨æˆ·ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰ç”¨æˆ·çš„æ•°æ®
        if not user_points_file or not os.path.exists(user_points_file):
            # æŸ¥æ‰¾dataç›®å½•ä¸‹æ‰€æœ‰ç”¨æˆ·çš„æ•°æ®
            data_dir = 'data'
            found_data = False
            combined_df = pd.DataFrame()

            if os.path.exists(data_dir):
                for user_dir in os.listdir(data_dir):
                    user_data_file = os.path.join(data_dir, user_dir, 'user_points.csv')
                    if os.path.exists(user_data_file):
                        try:
                            temp_df = pd.read_csv(user_data_file)
                            combined_df = pd.concat([combined_df, temp_df], ignore_index=True)
                            found_data = True
                        except:
                            continue

            if not found_data:
                return render_template('query_result.html',
                                     user_name=user_name,
                                     error_message="ç§¯åˆ†æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")

            df = combined_df
        else:
            df = pd.read_csv(user_points_file)
        df['UserID'] = df['UserID'].astype(str)

        # ç¡®ä¿æœ‰UserNameåˆ—
        if 'UserName' not in df.columns:
            return render_template('query_result.html',
                                 user_name=user_name,
                                 error_message="ç³»ç»Ÿæš‚ä¸æ”¯æŒç”¨æˆ·åæŸ¥è¯¢ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")

        # æŸ¥æ‰¾ç”¨æˆ·ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
        user_records = df[df['UserName'].str.contains(str(user_name), case=False, na=False)]

        if not user_records.empty:
            # å¦‚æœæ‰¾åˆ°å¤šä¸ªç”¨æˆ·ï¼Œè¿”å›æ‰€æœ‰åŒ¹é…çš„ç”¨æˆ·
            if len(user_records) > 1:
                users_list = []
                for _, user_info in user_records.iterrows():
                    users_list.append({
                        'UserID': user_info['UserID'],
                        'UserName': user_info['UserName'],
                        'TotalPoints': int(user_info['TotalPoints']),
                        'ValidDays': int(user_info['ValidDays']) if 'ValidDays' in user_info else 0
                    })

                return render_template('query_result.html',
                                     user_name=user_name,
                                     users_list=users_list,
                                     multiple=True,
                                     found=True,
                                     message=f"æ‰¾åˆ°{len(user_records)}ä¸ªåŒ¹é…çš„ç”¨æˆ·")

            # åªæ‰¾åˆ°ä¸€ä¸ªç”¨æˆ·
            user_info = user_records.iloc[0]
            return render_template('query_result.html',
                                 user_name=user_name,
                                 user_id=user_info['UserID'],
                                 user_display_name=user_info['UserName'],
                                 total_points=int(user_info['TotalPoints']),
                                 valid_days=int(user_info['ValidDays']) if 'ValidDays' in user_info else 0,
                                 multiple=False,
                                 found=True)
        else:
            return render_template('query_result.html',
                                 user_name=user_name,
                                 error_message=f"æœªæ‰¾åˆ°ç”¨æˆ·ååŒ…å«'{user_name}'çš„ç§¯åˆ†è®°å½•",
                                 found=False)

    except Exception as e:
        return render_template('query_result.html',
                             user_name=user_name,
                             error_message=f"æŸ¥è¯¢é”™è¯¯ï¼š{str(e)}")

# è¿è¡Œåº”ç”¨
if __name__ == '__main__':
    # å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œæ–¹ä¾¿å¼€å‘
    app.run(debug=True, host='0.0.0.0', port=5000)
